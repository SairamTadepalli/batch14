{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "from threading import Thread\n",
    "import playsound\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE_DOWNSAMPLE_RATIO = 1.5\n",
    "RESIZE_HEIGHT = 460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.27\n",
    "modelPath = \"models/shape_predictor_70_face_landmarks.dat\"\n",
    "sound_path = \"alarm.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(modelPath)\n",
    "\n",
    "leftEyeIndex = [36, 37, 38, 39, 40, 41]\n",
    "rightEyeIndex = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "blinkCount = 0\n",
    "drowsy = 0\n",
    "state = 0\n",
    "blinkTime = 0.15 #150ms\n",
    "drowsyTime = 1.5  #1200ms\n",
    "ALARM_ON = False\n",
    "GAMMA = 1.5\n",
    "threadStatusQ = queue.Queue()\n",
    "\n",
    "invGamma = 1.0/GAMMA\n",
    "table = np.array([((i / 255.0) ** invGamma) * 255 for i in range(0, 256)]).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(image):\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.equalizeHist(gray) \n",
    "\n",
    "def soundAlert(path, threadStatusQ):\n",
    "    while True:\n",
    "        if not threadStatusQ.empty():\n",
    "            FINISHED = threadStatusQ.get()\n",
    "            if FINISHED:\n",
    "                break\n",
    "        playsound.playsound(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    return ear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEyeStatus(landmarks):\n",
    "    mask = np.zeros(frame.shape[:2], dtype = np.float32)\n",
    "    \n",
    "    hullLeftEye = []\n",
    "    for i in range(0, len(leftEyeIndex)):\n",
    "        hullLeftEye.append((landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]))\n",
    "\n",
    "    cv2.fillConvexPoly(mask, np.int32(hullLeftEye), 255)\n",
    "\n",
    "    hullRightEye = []\n",
    "    for i in range(0, len(rightEyeIndex)):\n",
    "        hullRightEye.append((landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]))\n",
    "\n",
    "\n",
    "    cv2.fillConvexPoly(mask, np.int32(hullRightEye), 255)\n",
    "\n",
    "    # lenLeftEyeX = landmarks[leftEyeIndex[3]][0] - landmarks[leftEyeIndex[0]][0]\n",
    "    # lenLeftEyeY = landmarks[leftEyeIndex[3]][1] - landmarks[leftEyeIndex[0]][1]\n",
    "\n",
    "    # lenLeftEyeSquared = (lenLeftEyeX ** 2) + (lenLeftEyeY ** 2)\n",
    "    # eyeRegionCount = cv2.countNonZero(mask)\n",
    "\n",
    "    # normalizedCount = eyeRegionCount/np.float32(lenLeftEyeSquared)\n",
    "\n",
    "    #############################################################################\n",
    "    leftEAR = eye_aspect_ratio(hullLeftEye)\n",
    "    rightEAR = eye_aspect_ratio(hullRightEye)\n",
    "\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    #############################################################################\n",
    "\n",
    "    eyeStatus = 1          # 1 -> Open, 0 -> closed\n",
    "    if (ear < thresh):\n",
    "        eyeStatus = 0\n",
    "\n",
    "    return eyeStatus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
